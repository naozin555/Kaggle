{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cross Validation\n## 下記理由よりCross Validationする必要がある。\n- ## submit回数に制限がある。\n- ## publicの検証データで良い結果(submitで出るスコア)が出ても、privateの検証データ(最終的なランキングやメダル認定に用いるデータ)で良い結果が出るとは限らない。→publicの検証データに過学習しているかもしれない。"},{"metadata":{},"cell_type":"markdown","source":"# ホールドアウト検証（以前のコード）"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\ngender_submission = pd.read_csv('../input/titanic/gender_submission.csv')\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1       0.0       3   \n1            2       1.0       1   \n2            3       1.0       3   \n3            4       1.0       1   \n4            5       0.0       3   \n\n                                                Name  Sex   Age  SibSp  Parch  \\\n0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n4                           Allen, Mr. William Henry    0  35.0      0      0   \n\n             Ticket     Fare Cabin  Embarked  FamilySize  IsAlone  \n0         A/5 21171   7.2500   NaN         0           2        0  \n1          PC 17599  71.2833   C85         1           2        0  \n2  STON/O2. 3101282   7.9250   NaN         0           1        1  \n3            113803  53.1000  C123         0           2        0  \n4            373450   8.0500   NaN         0           1        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"delete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  FamilySize  IsAlone\n0       3    0  22.0      1      0   7.2500         0           2        0\n1       1    1  38.0      1      0  71.2833         1           2        0\n2       3    1  26.0      0      0   7.9250         0           1        1\n3       1    1  35.0      1      0  53.1000         0           2        0\n4       3    0  35.0      0      0   8.0500         0           1        1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### ホールドアウト検証(以前のコードのLightGBMの部分)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state=0, stratify=y_train)\n\n# ハイパーパラメータは手動調整済み\ncategorical_features = ['Embarked', 'Pclass', 'Sex']\nparams = {\n    'objective': 'binary',\n    'max_bin': 300,\n    'learning_rate': 0.05,\n    'num_leaves': 40\n}\n\nimport lightgbm as lgb\n\n\nlgb_train = lgb.Dataset(X_train, y_train,\n                                         categorical_feature=categorical_features)\nlgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train,\n                                        categorical_feature=categorical_features)\n\nmodel = lgb.train(params, lgb_train,\n                               valid_sets=[lgb_train, lgb_eval],\n                               verbose_eval=10,\n                               num_boost_round=1000,\n                               early_stopping_rounds=10)\n\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)","execution_count":5,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.505699\tvalid_1's binary_logloss: 0.532106\n[20]\ttraining's binary_logloss: 0.427825\tvalid_1's binary_logloss: 0.482279\n[30]\ttraining's binary_logloss: 0.377242\tvalid_1's binary_logloss: 0.456641\n[40]\ttraining's binary_logloss: 0.345424\tvalid_1's binary_logloss: 0.447083\n[50]\ttraining's binary_logloss: 0.323113\tvalid_1's binary_logloss: 0.440407\n[60]\ttraining's binary_logloss: 0.302727\tvalid_1's binary_logloss: 0.434527\n[70]\ttraining's binary_logloss: 0.285597\tvalid_1's binary_logloss: 0.434932\nEarly stopping, best iteration is:\n[66]\ttraining's binary_logloss: 0.293072\tvalid_1's binary_logloss: 0.433251\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred[:10]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array([0.03605598, 0.40306884, 0.10732166, 0.0802399 , 0.46011271,\n       0.20222002, 0.64929492, 0.11896033, 0.7452973 , 0.01917651])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (y_pred > 0.5).astype(int)\ny_pred[:10]","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/titanic/gender_submission.csv')\n\nsub['Survived'] = y_pred\nsub.to_csv('submission_lightgbm_holdout.csv', index=False)\n\nsub.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Cross Validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\ngender_submission = pd.read_csv('../input/titanic/gender_submission.csv')\n\ndata = pd.concat([train, test], sort=False)\n\ndata['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\ndata['Embarked'].fillna(('S'), inplace=True)\ndata['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\ndata['Fare'].fillna(np.mean(data['Fare']), inplace=True)\ndata['Age'].fillna(data['Age'].median(), inplace=True)\ndata['FamilySize'] = data['Parch'] + data['SibSp'] + 1\ndata['IsAlone'] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n\ndelete_columns = ['Name', 'PassengerId', 'Ticket', 'Cabin']\ndata.drop(delete_columns, axis=1, inplace=True)\n\ntrain = data[:len(train)]\ntest = data[len(train):]\n\ny_train = train['Survived']\nX_train = train.drop('Survived', axis=1)\nX_test = test.drop('Survived', axis=1)\n\nX_train.head()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"   Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  FamilySize  IsAlone\n0       3    0  22.0      1      0   7.2500         0           2        0\n1       1    1  38.0      1      0  71.2833         1           2        0\n2       3    1  26.0      0      0   7.9250         0           1        1\n3       1    1  35.0      1      0  53.1000         0           2        0\n4       3    0  35.0      0      0   8.0500         0           1        1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>0</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### KFold\nKFoldを用いる事でtrain_test_split()を複数回用いて、交差検証用のデータを作らなくてよくなる"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n# 各分割でのX_testに対する予測値を格納するリスト\ny_preds = []\n# 各分割での学習したモデルを格納するリスト\nmodels = []\n# 各分割での検証用データセットに予測値を格納するリスト（0で初期化）\n# oof(out of fold)：交差検証用において、学習用データを、さらに学習用データと検証用データに分割した時に、学習に使われなかったデータ\noof_train = np.zeros((len(X_train),))\n\n# n_splits:分割数\n# shuffle：分割前にデータをシャッフルするかどうか\ncv = KFold(n_splits=5, shuffle=True, random_state=0)\n\ncategorical_features = ['Embarked', 'Pclass', 'Sex']\n\nparams = {\n    'objective': 'binary',\n    'max_bin': 300,\n    'learning_rate': 0.05,\n    'num_leaves': 40\n}\n\n# fold_idは分割して学習したモデルを個別に保存する場合にファイル名に用いられることが多い（今回は未使用）\n# 分割後のイテラブルオブジェクトはインデックスなので、データを抽出しなければならないことに注意、インデックスの指定方法もDFとndaaryで異なる\nfor fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n    # データフレーム\n    X_tr = X_train.loc[train_index, :]\n    X_val = X_train.loc[valid_index, :]\n    # numpy.ndarray\n    y_tr = y_train[train_index]\n    y_val = y_train[valid_index]\n\n    lgb_train = lgb.Dataset(X_tr, y_tr,\n                                             categorical_feature=categorical_features)\n    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train,\n                                            categorical_feature=categorical_features)\n\n    model = lgb.train(params, lgb_train,\n                                   valid_sets=[lgb_train, lgb_eval],\n                                   verbose_eval=10,\n                                   num_boost_round=1000,\n                                   early_stopping_rounds=10)\n\n    # CrossValidationの検証用データセット（X_val）に対する予測値を格納(冒頭で0で初期化したリストに代入)\n    oof_train[valid_index] = model.predict(X_val, num_iteration=model.best_iteration)\n    \n    # 各分割でのX_test（最初に用意した評価用のデータセット）に対する予測値を格納\n    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n    y_preds.append(y_pred)\n    \n    # 各分割で学習したモデルを格納\n    models.append(model)","execution_count":10,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n","name":"stderr"},{"output_type":"stream","text":"Training until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.506339\tvalid_1's binary_logloss: 0.516198\n[20]\ttraining's binary_logloss: 0.428668\tvalid_1's binary_logloss: 0.446596\n[30]\ttraining's binary_logloss: 0.383412\tvalid_1's binary_logloss: 0.411961\n[40]\ttraining's binary_logloss: 0.35367\tvalid_1's binary_logloss: 0.397122\n[50]\ttraining's binary_logloss: 0.329451\tvalid_1's binary_logloss: 0.391041\n[60]\ttraining's binary_logloss: 0.307092\tvalid_1's binary_logloss: 0.38325\n[70]\ttraining's binary_logloss: 0.290771\tvalid_1's binary_logloss: 0.377067\n[80]\ttraining's binary_logloss: 0.274935\tvalid_1's binary_logloss: 0.373918\n[90]\ttraining's binary_logloss: 0.260335\tvalid_1's binary_logloss: 0.370602\nEarly stopping, best iteration is:\n[85]\ttraining's binary_logloss: 0.267203\tvalid_1's binary_logloss: 0.369116\nTraining until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.504211\tvalid_1's binary_logloss: 0.534594\n[20]\ttraining's binary_logloss: 0.422236\tvalid_1's binary_logloss: 0.481243\n[30]\ttraining's binary_logloss: 0.37173\tvalid_1's binary_logloss: 0.459512\n[40]\ttraining's binary_logloss: 0.341914\tvalid_1's binary_logloss: 0.453871\n[50]\ttraining's binary_logloss: 0.318699\tvalid_1's binary_logloss: 0.451806\n[60]\ttraining's binary_logloss: 0.296894\tvalid_1's binary_logloss: 0.449685\nEarly stopping, best iteration is:\n[58]\ttraining's binary_logloss: 0.301388\tvalid_1's binary_logloss: 0.449112\nTraining until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.506747\tvalid_1's binary_logloss: 0.507713\n[20]\ttraining's binary_logloss: 0.42895\tvalid_1's binary_logloss: 0.449278\n[30]\ttraining's binary_logloss: 0.384356\tvalid_1's binary_logloss: 0.41254\n[40]\ttraining's binary_logloss: 0.355218\tvalid_1's binary_logloss: 0.396228\n[50]\ttraining's binary_logloss: 0.333925\tvalid_1's binary_logloss: 0.387799\n[60]\ttraining's binary_logloss: 0.313799\tvalid_1's binary_logloss: 0.385787\n[70]\ttraining's binary_logloss: 0.298536\tvalid_1's binary_logloss: 0.38534\n[80]\ttraining's binary_logloss: 0.283249\tvalid_1's binary_logloss: 0.383338\n[90]\ttraining's binary_logloss: 0.270355\tvalid_1's binary_logloss: 0.385343\nEarly stopping, best iteration is:\n[80]\ttraining's binary_logloss: 0.283249\tvalid_1's binary_logloss: 0.383338\nTraining until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.497977\tvalid_1's binary_logloss: 0.525947\n[20]\ttraining's binary_logloss: 0.416873\tvalid_1's binary_logloss: 0.471473\n[30]\ttraining's binary_logloss: 0.368347\tvalid_1's binary_logloss: 0.446558\n[40]\ttraining's binary_logloss: 0.338844\tvalid_1's binary_logloss: 0.437886\n[50]\ttraining's binary_logloss: 0.318398\tvalid_1's binary_logloss: 0.437554\nEarly stopping, best iteration is:\n[41]\ttraining's binary_logloss: 0.336795\tvalid_1's binary_logloss: 0.437121\nTraining until validation scores don't improve for 10 rounds\n[10]\ttraining's binary_logloss: 0.494316\tvalid_1's binary_logloss: 0.552225\n[20]\ttraining's binary_logloss: 0.417327\tvalid_1's binary_logloss: 0.487758\n[30]\ttraining's binary_logloss: 0.370965\tvalid_1's binary_logloss: 0.453038\n[40]\ttraining's binary_logloss: 0.341695\tvalid_1's binary_logloss: 0.439283\n[50]\ttraining's binary_logloss: 0.319843\tvalid_1's binary_logloss: 0.4351\n[60]\ttraining's binary_logloss: 0.301123\tvalid_1's binary_logloss: 0.435584\nEarly stopping, best iteration is:\n[51]\ttraining's binary_logloss: 0.31821\tvalid_1's binary_logloss: 0.4347\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# oof_trainをcsv形式で保存　（事前にndarrayからdfに変換しておく）\npd.DataFrame(oof_train).to_csv('oof_train_kfold.csv', index=False)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"各モデルの検証用データセットに対する性能(損失関数の値)を表示、CVスコアとして平均も表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = [\n    m.best_score['valid_1']['binary_logloss'] for m in models\n]\nscore = sum(scores) / len(scores)\nprint('===CV scores===')\nprint(scores)\nprint(score)","execution_count":12,"outputs":[{"output_type":"stream","text":"===CV scores===\n[0.3691161193267496, 0.4491122965802196, 0.3833384988458873, 0.43712149656630833, 0.43469994547894103]\n0.41467767135962114\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"性能を、正解率で表示"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n\ny_pred_oof = (oof_train > 0.5).astype(int)\naccuracy_score(y_train, y_pred_oof)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.8226711560044894"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"各分割での予測値を平均した値を、最終的なsubmitとする"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_sub = sum(y_preds) / len(y_preds)\ny_sub = (y_sub > 0.5).astype(int)\nsub['Survived'] = y_sub\nsub.to_csv('submission_lightgbm_kfold.csv', index=False)\nsub.head()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# 結果の比較\n## 交差検証を用いると精度が向上したことが分かる\n- クロスバリデーション未使用時：0.76315\n- クロスバリデーション適用時：0.76794"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}